{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Getting Started: Import a labeled dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Getting started \n",
        "## Importing a labeled dataset\n",
        "---"
      ],
      "metadata": {
        "id": "F5Zex-ktX5ME"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6rdGGv8m-lz"
      },
      "outputs": [],
      "source": [
        "!pip3 install labelbox[data]\n",
        "import labelbox\n",
        "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification,Option\n",
        "from labelbox.schema.annotation_import import MALPredictionImport\n",
        "from labelbox.data.serialization import NDJsonConverter\n",
        "from labelbox.schema.annotation_import import LabelImport\n",
        "from labelbox import LabelingFrontend\n",
        "from labelbox.data.annotation_types import (\n",
        "    Label,\n",
        "    Point,\n",
        "    LabelList,\n",
        "    ImageData,\n",
        "    Rectangle,\n",
        "    ObjectAnnotation,\n",
        ")\n",
        "from labelbox.schema.data_row_metadata import (\n",
        "    DataRowMetadata,\n",
        "    DataRowMetadataField,\n",
        "    DeleteDataRowMetadata,\n",
        "    DataRowMetadataKind\n",
        ")\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import datetime\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Generic data download function\n",
        "def download_files(filemap):\n",
        "    path, uri = filemap    \n",
        "    ## Download data\n",
        "    if not os.path.exists(path):\n",
        "        r = requests.get(uri, stream=True)\n",
        "        if r.status_code == 200:\n",
        "            with open(path, 'wb') as f:\n",
        "                for chunk in r:\n",
        "                    f.write(chunk)\n",
        "    return path"
      ],
      "metadata": {
        "id": "HiKZnB4YPqHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Labelbox client"
      ],
      "metadata": {
        "id": "PqJt-G_aS-Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Generate API key: https://app.labelbox.com/account/api-keys\n",
        "LB_API_KEY = \"\"\n",
        "client = labelbox.Client(LB_API_KEY)\n",
        "\n",
        "DATA_ROWS = \"https://storage.googleapis.com/labelbox-datasets/VHR_geospatial/geospatial_datarows.json\"\n",
        "ANNOTATIONS = \"https://storage.googleapis.com/labelbox-datasets/VHR_geospatial/geospatial_annotations.json\""
      ],
      "metadata": {
        "id": "wiwPkXe4nJrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download a public dataset"
      ],
      "metadata": {
        "id": "u5kXlyspS5GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_files((\"data_rows.json\", DATA_ROWS))\n",
        "download_files((\"annotations.json\", ANNOTATIONS))"
      ],
      "metadata": {
        "id": "UEXN2pyt3YZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data_rows.json', 'r') as fp:\n",
        "    data_rows = json.load(fp)\n",
        "\n",
        "with open('annotations.json', 'r') as fp:\n",
        "    annotations = json.load(fp)"
      ],
      "metadata": {
        "id": "OfWoTuKeUX8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a dataset"
      ],
      "metadata": {
        "id": "V-VfjDaRSYtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = client.create_dataset(name=\"Geospatial vessel detection\")"
      ],
      "metadata": {
        "id": "ldzBOurIn8Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data Rows with Metadata"
      ],
      "metadata": {
        "id": "zewMUN9WScOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is an example of adding two metadata fields to your Data Rows: a \"captureDateTime\" field with datetime value, and a \"tag\" field with string value\n",
        "metadata_ontology = client.get_data_row_metadata_ontology()\n",
        "datetime_schema_id = metadata_ontology.reserved_by_name[\"captureDateTime\"].uid\n",
        "tag_schema_id = metadata_ontology.reserved_by_name[\"tag\"].uid\n",
        "tag_items = [\"WorldView-1\", \"WorldView-2\", \"WorldView-3\", \"WorldView-4\"]\n",
        "\n",
        "for datarow in tqdm(data_rows):\n",
        "    dt = datetime.datetime.utcnow() + datetime.timedelta(days=random.random()*30) # this is random datetime value\n",
        "    tag_item = random.choice(tag_items) # this is a random tag value\n",
        "\n",
        "    # Option 1: Specify metadata with a list of DataRowMetadataField. This is the recommended option since it comes with validation for metadata fields.\n",
        "    metadata_fields = [\n",
        "                       DataRowMetadataField(schema_id=datetime_schema_id, value=dt), \n",
        "                       DataRowMetadataField(schema_id=tag_schema_id, value=tag_item)\n",
        "                       ]\n",
        "\n",
        "    # Option 2: Uncomment to try. Alternatively, you can specify the metadata fields with dictionary format without declaring the DataRowMetadataField objects. It is equivalent to Option 1.\n",
        "    # metadata_fields = [\n",
        "    #                    {\"schema_id\": datetime_schema_id, \"value\": dt}, \n",
        "    #                    {\"schema_id\": tag_schema_id, \"value\": tag_item}\n",
        "    #                    ]\n",
        "\n",
        "    datarow[\"metadata_fields\"] = metadata_fields"
      ],
      "metadata": {
        "id": "_7JnTZMQ6Mnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = dataset.create_data_rows(data_rows)\n",
        "task.wait_till_done()"
      ],
      "metadata": {
        "id": "5_CrtIGqUimL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine a Data Row"
      ],
      "metadata": {
        "id": "xpF4vH4eUkPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datarow = next(dataset.data_rows())\n",
        "print(datarow)"
      ],
      "metadata": {
        "id": "HGdJZLYoUmKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup a labeling project"
      ],
      "metadata": {
        "id": "p4VjfJKESeoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ontology = OntologyBuilder()\n",
        "\n",
        "for tool in annotations['categories']:\n",
        "  print(tool['name'])\n",
        "  ontology.add_tool(Tool(tool = Tool.Type.BBOX, name = tool['name']))\n",
        "\n",
        "ontology = client.create_ontology(\"Vessel detection ontology\", ontology.asdict())\n",
        "project = client.create_project(name = \"Vessel detection\")\n",
        "project.setup_editor(ontology)\n",
        "ontology_from_project = OntologyBuilder.from_project(project)"
      ],
      "metadata": {
        "id": "4PR2sWSL-L7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare and queue batch of Data Rows to the project"
      ],
      "metadata": {
        "id": "xvq-ndx1HSDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project.update(queue_mode=project.QueueMode.Batch)\n",
        "data_rows = [dr.uid for dr in list(dataset.export_data_rows())]\n",
        "\n",
        "# Randomly select 200 Data Rows\n",
        "sampled_data_rows = random.sample(data_rows, 200)\n",
        "\n",
        "batch = project.create_batch(\n",
        "  \"Initial batch\", # name of the batch\n",
        "  sampled_data_rows, # list of Data Rows\n",
        "  1 # priority between 1-5\n",
        ")"
      ],
      "metadata": {
        "id": "YARsP1NZHRWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process ground truth annotations for import"
      ],
      "metadata": {
        "id": "BkCFk7qUSu53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queued_data_rows = project.export_queued_data_rows()\n",
        "ground_truth_list = LabelList()\n",
        "\n",
        "for datarow in queued_data_rows:\n",
        "  annotations_list = []\n",
        "  folder = datarow['externalId'].split(\"/\")[0]\n",
        "  id = datarow['externalId'].split(\"/\")[1]\n",
        "  if folder == \"positive_image_set\":\n",
        "    for image in annotations['images']:\n",
        "      if (image['file_name']==id):\n",
        "        for annotation in annotations['annotations']:\n",
        "          if annotation['image_id'] == image['id']:\n",
        "            bbox = annotation['bbox']\n",
        "            id = annotation['category_id'] - 1\n",
        "            class_name = ontology_from_project.tools[id].name\n",
        "            annotations_list.append(ObjectAnnotation(\n",
        "                name = class_name,\n",
        "                value = Rectangle(start = Point(x = bbox[0], y = bbox[1]), end = Point(x = bbox[2]+bbox[0], y = bbox[3]+bbox[1])),\n",
        "            ))\n",
        "  image = ImageData(uid = datarow['id'])\n",
        "  ground_truth_list.append(Label(data = image, annotations = annotations_list))"
      ],
      "metadata": {
        "id": "fmeFTCk7-Vrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import ground truth annotation"
      ],
      "metadata": {
        "id": "GCDxiydHSzeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_list.assign_feature_schema_ids(OntologyBuilder.from_project(project))\n",
        "ground_truth_ndjson = list(NDJsonConverter.serialize(ground_truth_list))\n",
        "\n",
        "start_time = time.time()\n",
        "## Upload annotations\n",
        "upload_task = LabelImport.create_from_objects(client, project.uid, \"geospatial-import-job-1\", ground_truth_ndjson)\n",
        "print(upload_task)\n",
        "\n",
        "#Wait for upload to finish (Will take up to five minutes)\n",
        "upload_task.wait_until_done()\n",
        "print(upload_task.errors)\n",
        "print(\"--- Finished in %s mins ---\" % ((time.time() - start_time)/60))"
      ],
      "metadata": {
        "id": "71WXNj6FB60-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# queued_data_rows = [dr['id'] for dr in list(project.export_queued_data_rows())]\n",
        "# data_rows = [dr.uid for dr in list(dataset.export_data_rows())]\n",
        "# data_rows_not_queued = list(set(data_rows)- set(queued_data_rows))\n",
        "\n",
        "# # Randomly select 200 Data Rows\n",
        "# sampled_data_rows = random.sample(data_rows_not_queued, 200)\n",
        "\n",
        "# batch = project.create_batch(\n",
        "#   \"Second batch\", # name of the batch\n",
        "#   sampled_data_rows, # list of Data Rows\n",
        "#   5 # priority between 1-5\n",
        "# )\n"
      ],
      "metadata": {
        "id": "LEU2CTtlWRL_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}